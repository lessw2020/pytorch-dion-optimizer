{
  "dion": [
    {
      "step": 0,
      "loss": 10.892661094665527,
      "learning_rate": 0.01,
      "grad_norm": 0.6727918741796823,
      "wall_time": 0.6575062274932861,
      "memory_used": 1211.69580078125
    },
    {
      "step": 10,
      "loss": 9.969836235046387,
      "learning_rate": 0.01,
      "grad_norm": 0.6331134372612196,
      "wall_time": 1.0159962177276611,
      "memory_used": 1211.69580078125
    },
    {
      "step": 20,
      "loss": 8.270310401916504,
      "learning_rate": 0.01,
      "grad_norm": 0.6101815033117788,
      "wall_time": 1.3631415367126465,
      "memory_used": 1211.69580078125
    },
    {
      "step": 30,
      "loss": 6.297362327575684,
      "learning_rate": 0.01,
      "grad_norm": 0.5791787797965559,
      "wall_time": 1.7047336101531982,
      "memory_used": 1211.69580078125
    },
    {
      "step": 40,
      "loss": 4.56975793838501,
      "learning_rate": 0.01,
      "grad_norm": 0.49948540595634816,
      "wall_time": 2.045694589614868,
      "memory_used": 1211.69580078125
    },
    {
      "step": 50,
      "loss": 3.5285046100616455,
      "learning_rate": 0.01,
      "grad_norm": 0.4480876218548933,
      "wall_time": 2.384089708328247,
      "memory_used": 1211.69580078125
    },
    {
      "step": 60,
      "loss": 3.012704372406006,
      "learning_rate": 0.01,
      "grad_norm": 0.43653437403115997,
      "wall_time": 2.724738836288452,
      "memory_used": 1211.69580078125
    },
    {
      "step": 70,
      "loss": 2.6529672145843506,
      "learning_rate": 0.01,
      "grad_norm": 0.4418726492445018,
      "wall_time": 3.0655808448791504,
      "memory_used": 1211.69580078125
    },
    {
      "step": 80,
      "loss": 2.4553401470184326,
      "learning_rate": 0.01,
      "grad_norm": 0.4159845274321563,
      "wall_time": 3.4038007259368896,
      "memory_used": 1211.69580078125
    },
    {
      "step": 90,
      "loss": 2.2968575954437256,
      "learning_rate": 0.01,
      "grad_norm": 0.3762162541326182,
      "wall_time": 3.74245285987854,
      "memory_used": 1211.69580078125
    },
    {
      "step": 99,
      "loss": 2.2768120765686035,
      "learning_rate": 0.01,
      "grad_norm": 0.3818223699819877,
      "wall_time": 4.047768592834473,
      "memory_used": 1211.69580078125
    }
  ],
  "adamw": [
    {
      "step": 0,
      "loss": 10.880025863647461,
      "learning_rate": 0.0002,
      "grad_norm": 0.6752852010691294,
      "wall_time": 0.10040426254272461,
      "memory_used": 1741.39111328125
    },
    {
      "step": 10,
      "loss": 10.540284156799316,
      "learning_rate": 0.0002,
      "grad_norm": 0.4794742810091439,
      "wall_time": 0.30414748191833496,
      "memory_used": 1740.51611328125
    },
    {
      "step": 20,
      "loss": 10.131644248962402,
      "learning_rate": 0.0002,
      "grad_norm": 0.42851434176663233,
      "wall_time": 0.5077600479125977,
      "memory_used": 1740.51611328125
    },
    {
      "step": 30,
      "loss": 9.784619331359863,
      "learning_rate": 0.0002,
      "grad_norm": 0.45463112813024475,
      "wall_time": 0.7121224403381348,
      "memory_used": 1740.51611328125
    },
    {
      "step": 40,
      "loss": 9.486592292785645,
      "learning_rate": 0.0002,
      "grad_norm": 0.45922491127720183,
      "wall_time": 0.9169611930847168,
      "memory_used": 1740.51611328125
    },
    {
      "step": 50,
      "loss": 9.21857738494873,
      "learning_rate": 0.0002,
      "grad_norm": 0.48935387498453414,
      "wall_time": 1.120248556137085,
      "memory_used": 1740.51611328125
    },
    {
      "step": 60,
      "loss": 8.96893310546875,
      "learning_rate": 0.0002,
      "grad_norm": 0.47948324162543243,
      "wall_time": 1.3230490684509277,
      "memory_used": 1740.51611328125
    },
    {
      "step": 70,
      "loss": 8.711746215820312,
      "learning_rate": 0.0002,
      "grad_norm": 0.49693305908908864,
      "wall_time": 1.5259742736816406,
      "memory_used": 1740.51611328125
    },
    {
      "step": 80,
      "loss": 8.45991325378418,
      "learning_rate": 0.0002,
      "grad_norm": 0.5001021652647561,
      "wall_time": 1.7306203842163086,
      "memory_used": 1740.51611328125
    },
    {
      "step": 90,
      "loss": 8.20776081085205,
      "learning_rate": 0.0002,
      "grad_norm": 0.4911242000348289,
      "wall_time": 1.9374289512634277,
      "memory_used": 1740.51611328125
    },
    {
      "step": 99,
      "loss": 7.982591152191162,
      "learning_rate": 0.0002,
      "grad_norm": 0.491348542479941,
      "wall_time": 2.119501829147339,
      "memory_used": 1740.51611328125
    }
  ]
}